In [1]: import numpy as np
   ...: import pandas as pd
   ...: import matplotlib.pyplot as plt
   ...: 
   ...: from datetime import date
   ...: from nsepy import get_history
   ...: 
   ...: dataset = get_history(symbol="NIFTY", 
   ...:                     start=date(2015,1,1), 
   ...:                     end=date(2015,12,31),
   ...: 					index=True)

In [2]: X=dataset.iloc[:,[0,1,2,4,5]].values
   ...: y=dataset.iloc[:,3].values

In [3]: from sklearn.cross_validation import train_test_saplit
   ...: X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)
   ...: 
   ...: from sklearn.linear_model import LinearRegression
   ...: regressor = LinearRegression()
   ...: regressor.fit(X_train,y_train)
   ...: 
   ...: y_pred=regressor.predict(X_test)
/home/aditya/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
Traceback (most recent call last):

  File "<ipython-input-3-f3334883dcfe>", line 1, in <module>
    from sklearn.cross_validation import train_test_saplit

ImportError: cannot import name 'train_test_saplit'


In [4]: 

In [4]: from sklearn.model_selection import train_test_saplit
   ...: X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)
   ...: 
   ...: from sklearn.linear_model import LinearRegression
   ...: regressor = LinearRegression()
   ...: regressor.fit(X_train,y_train)
   ...: 
   ...: y_pred=regressor.predict(X_test)
Traceback (most recent call last):

  File "<ipython-input-4-8144d5f8f44a>", line 1, in <module>
    from sklearn.model_selection import train_test_saplit

ImportError: cannot import name 'train_test_saplit'


In [5]: 

In [5]: from sklearn.model_selection import train_test_split
   ...: X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)
   ...: 
   ...: from sklearn.linear_model import LinearRegression
   ...: regressor = LinearRegression()
   ...: regressor.fit(X_train,y_train)
   ...: 
   ...: y_pred=regressor.predict(X_test)

In [6]: import statsmodels.formula.api as sm
   ...: X=np.append(arr=X,values=np.ones((248,1)).astype(int),axis=1)

In [7]: Xopt=X[:,[0,1,2,4,5]]
   ...: regressor_OLS=sm.OLS(endog=y,exog=Xopt).fit()
   ...: regressor_OLS.summary()
Out[7]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.994
Model:                            OLS   Adj. R-squared:                  0.994
Method:                 Least Squares   F-statistic:                 1.070e+04
Date:                Mon, 08 Oct 2018   Prob (F-statistic):          8.53e-272
Time:                        09:22:30   Log-Likelihood:                -1161.0
No. Observations:                 248   AIC:                             2332.
Df Residuals:                     243   BIC:                             2349.
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.6600      0.045    -14.551      0.000      -0.749      -0.571
x2             0.8281      0.055     15.055      0.000       0.720       0.936
x3             0.8335      0.040     20.807      0.000       0.755       0.912
x4         -1.013e-11   6.84e-11     -0.148      0.882   -1.45e-10    1.25e-10
const         -6.7702     40.651     -0.167      0.868     -86.844      73.304
==============================================================================
Omnibus:                       59.677   Durbin-Watson:                   2.161
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              214.242
Skew:                           0.957   Prob(JB):                     3.01e-47
Kurtosis:                       7.132   Cond. No.                     2.05e+12
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.05e+12. This might indicate that there are
strong multicollinearity or other numerical problems.
"""

In [8]: Xopt=X[:,[1,2,4,5]]
   ...: regressor_OLS=sm.OLS(endog=y,exog=Xopt).fit()
   ...: regressor_OLS.summary()
Out[8]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.989
Model:                            OLS   Adj. R-squared:                  0.989
Method:                 Least Squares   F-statistic:                     7615.
Date:                Mon, 08 Oct 2018   Prob (F-statistic):          1.05e-240
Time:                        09:24:43   Log-Likelihood:                -1238.7
No. Observations:                 248   AIC:                             2485.
Df Residuals:                     244   BIC:                             2499.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.2741      0.054      5.057      0.000       0.167       0.381
x2             0.7235      0.054     13.472      0.000       0.618       0.829
x3          1.945e-11   9.33e-11      0.208      0.835   -1.64e-10    2.03e-10
const         39.5348     55.326      0.715      0.476     -69.443     148.512
==============================================================================
Omnibus:                        8.016   Durbin-Watson:                   2.197
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.192
Skew:                           0.420   Prob(JB):                       0.0166
Kurtosis:                       2.703   Cond. No.                     2.04e+12
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.04e+12. This might indicate that there are
strong multicollinearity or other numerical problems.
"""

In [9]: Xopt=X[:,[2,4,5]]
   ...: regressor_OLS=sm.OLS(endog=y,exog=Xopt).fit()
   ...: regressor_OLS.summary()
Out[9]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.988
Model:                            OLS   Adj. R-squared:                  0.988
Method:                 Least Squares   F-statistic:                 1.037e+04
Date:                Mon, 08 Oct 2018   Prob (F-statistic):          1.74e-237
Time:                        09:25:20   Log-Likelihood:                -1251.0
No. Observations:                 248   AIC:                             2508.
Df Residuals:                     245   BIC:                             2519.
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.9930      0.007    141.696      0.000       0.979       1.007
x2           1.86e-10   9.16e-11      2.030      0.043    5.54e-12    3.66e-10
const         91.3888     57.029      1.603      0.110     -20.941     203.718
==============================================================================
Omnibus:                       37.961   Durbin-Watson:                   2.170
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.339
Skew:                           1.056   Prob(JB):                     1.17e-11
Kurtosis:                       3.639   Cond. No.                     2.01e+12
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.01e+12. This might indicate that there are
strong multicollinearity or other numerical problems.
"""

In [10]: Xopt=X[:,[4,5]]
    ...: regressor_OLS=sm.OLS(endog=y,exog=Xopt).fit()
    ...: regressor_OLS.summary()
Out[10]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.032
Model:                            OLS   Adj. R-squared:                  0.028
Method:                 Least Squares   F-statistic:                     8.014
Date:                Mon, 08 Oct 2018   Prob (F-statistic):            0.00502
Time:                        09:26:21   Log-Likelihood:                -1798.9
No. Observations:                 248   AIC:                             3602.
Df Residuals:                     246   BIC:                             3609.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1          2.325e-09   8.21e-10      2.831      0.005    7.07e-10    3.94e-09
const       8099.4103     69.395    116.715      0.000    7962.726    8236.094
==============================================================================
Omnibus:                       67.496   Durbin-Watson:                   0.119
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.446
Skew:                          -0.077   Prob(JB):                      0.00198
Kurtosis:                       1.914   Cond. No.                     2.69e+11
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.69e+11. This might indicate that there are
strong multicollinearity or other numerical problems.
"""
